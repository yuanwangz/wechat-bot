import schedule from "node-schedule"
import { requestPromise } from './req.js'
import * as dotenv from 'dotenv' // see https://github.com/motdotla/dotenv#how-do-i-use-dotenv-with-import
import chokidar from 'chokidar';
dotenv.config()

let API = process.env.PROXY_API ? process.env.PROXY_API : 'https://api.openai.com';
let OPENAI_MODEL = process.env.OPENAI_API_MODEL ? process.env.OPENAI_API_MODEL : 'gpt-3.5-turbo-16k';
let CUSTOM_PROMPT = process.env.CUSTOM_PROMPT ? process.env.CUSTOM_PROMPT : 'ä½ æ˜¯ChatGPT, ä¸€ä¸ªç”±OpenAIè®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹, ä½ æ—¨åœ¨å›ç­”å¹¶è§£å†³äººä»¬çš„ä»»ä½•é—®é¢˜ï¼Œå¹¶ä¸”å¯ä»¥ä½¿ç”¨å¤šç§è¯­è¨€ä¸äººäº¤æµã€‚';
let ADMIN_WECHAT = process.env.ADMIN_WECHAT ? process.env.ADMIN_WECHAT : '';
let API_KEY = process.env.OPENAI_API_KEY
const watcher = chokidar.watch('.env');
watcher.on('change', (path) => {
  console.log(`File ${path} has been changed`);
  delete process.env.PROXY_API;
  delete process.env.OPENAI_API_MODEL;
  delete process.env.CUSTOM_PROMPT;
  delete process.env.ADMIN_WECHAT;
  delete process.env.OPENAI_API_KEY;
  dotenv.config();
  API = process.env.PROXY_API ? process.env.PROXY_API : 'https://api.openai.com';
  OPENAI_MODEL = process.env.OPENAI_API_MODEL ? process.env.OPENAI_API_MODEL : 'gpt-3.5-turbo-16k';
  CUSTOM_PROMPT = process.env.CUSTOM_PROMPT ? process.env.CUSTOM_PROMPT : 'ä½ æ˜¯ChatGPT, ä¸€ä¸ªç”±OpenAIè®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹, ä½ æ—¨åœ¨å›ç­”å¹¶è§£å†³äººä»¬çš„ä»»ä½•é—®é¢˜ï¼Œå¹¶ä¸”å¯ä»¥ä½¿ç”¨å¤šç§è¯­è¨€ä¸äººäº¤æµã€‚';
  ADMIN_WECHAT = process.env.ADMIN_WECHAT ? process.env.ADMIN_WECHAT : '';
  API_KEY = process.env.OPENAI_API_KEY
});
let systemMessage = {
  role: 'system',
  content: CUSTOM_PROMPT,
}

const conversationPool = new Map();

async function chatgptReply(wxid, id, nick, rawmsg,file,addHis,prompt) {
  console.log(`chat:${wxid}-------${id}\nrawmsg: ${rawmsg}`);
  let response = 'ğŸ¤’ğŸ¤’ğŸ¤’å‡ºäº†ä¸€ç‚¹å°é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•ä¸‹...';
  let temp_model = null;
  if (rawmsg === "æ¸…é™¤æ‰€æœ‰å¯¹è¯" && id === ADMIN_WECHAT) {
    conversationPool.clear()
    response = `æ‰€æœ‰çš„å¯¹è¯å·²æ¸…ç©º`
    return response
  } else if (rawmsg === "ç»“æŸå¯¹è¯") {
    conversationPool.delete(wxid);
    response = `${nick}çš„å¯¹è¯å·²ç»“æŸ`
    return response
  } else {
	if(file){
		rawmsg = [
                {
                    "type": "text",
                    "text": ""+rawmsg+""
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": ""+file+""
                    }
                }
            ]
	}
    const datatime = Date.now()
	let messages;
    if(prompt){
      let newsystemMessage = {
        role: 'system',
        content: prompt,
      }
      messages = [newsystemMessage];
      if (addHis) {
        messages.push({ role: 'assistant', content: addHis });
      }
      messages.push({ role: 'user', content: rawmsg });
    }else{
      if (conversationPool.get(wxid)) {
        messages = [...conversationPool.get(wxid).messages];
        if (addHis) {
          messages.push({ role: 'assistant', content: addHis });
        }
        messages.push({ role: 'user', content: rawmsg });
      } else {
        messages = [systemMessage];
        if (addHis) {
          messages.push({ role: 'assistant', content: addHis });
        }
        messages.push({ role: 'user', content: rawmsg });
      }
    }
    let newMessage = { datatime: datatime, messages };
    let stream = true;
    const data = { model: temp_model==null?OPENAI_MODEL:temp_model, messages, stream: stream };
    let raw_response;
    let response = '';
    try {
      if (stream) {
        // æµå¼å“åº”å¤„ç†
        const streamResponse = await requestPromise({
          url: `${API}/v1/chat/completions`,
          headers: {
            'Authorization': `Bearer ${API_KEY}`,
            'Content-Type': 'application/json',
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Mobile/15E148 Safari/604.1'
          },
          body: data,
          method: 'POST',
          responseType: 'arraybuffer'  // ä½¿ç”¨ arraybuffer æ¥æ¥æ”¶åŸå§‹æ•°æ®
        });

        // å°† arraybuffer è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        const responseText = streamResponse.data.toString('utf-8');

        // æŒ‰è¡Œåˆ†å‰²å“åº”
        const lines = responseText.split('\n');

        for (const line of lines) {
          if (line.trim() === 'data: [DONE]') {
            break;
          }
          if (line.startsWith('data: ')) {
            try {
              const parsedData = JSON.parse(line.slice(6));
              if (parsedData.choices && parsedData.choices.length > 0 && parsedData.choices[0].delta.content) {
                response += parsedData.choices[0].delta.content;
              }
            } catch (error) {
              console.error('Error parsing stream data:', error);
            }
          }
        }
      } else {
        // éæµå¼å“åº”å¤„ç†
        const nonStreamResponse = await requestPromise({
          url: `${API}/v1/chat/completions`,
          headers: {
            'Authorization': `Bearer ${API_KEY}`,
            'Content-Type': 'application/json',
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Mobile/15E148 Safari/604.1'
          },
          body: data,
          method: 'POST'
        });

        if (nonStreamResponse.data.choices && nonStreamResponse.data.choices.length > 0) {
          response = nonStreamResponse.data.choices[0].message.content;
        } else {
          console.log('Invalid response:', nonStreamResponse);
          response = 'ğŸ¤’ğŸ¤’ğŸ¤’å‡ºäº†ä¸€ç‚¹å°é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•ä¸‹...';
        }
      }

      console.log(`chat:${wxid}------${id}\nresponse: ${response}`);

      // åªæœ‰åœ¨æˆåŠŸè·å–åˆ°å›å¤æ—¶ï¼Œæ‰å°†åŸå§‹æ¶ˆæ¯æ·»åŠ åˆ°å¯¹è¯æ± ä¸­
      if (response && !prompt) {
        conversationPool.set(wxid, newMessage);
      }
      if (!prompt) {
        conversationPool.get(wxid).messages.push({ role: 'assistant', content: response });
      }
    } catch (e) {
      console.error('Error in processing:', e);
      if (e.response && e.response.data) {
        console.log(e.response.data.error);
      } else {
        console.log(e.response || e);
      }
      response = 'ğŸ¤’ğŸ¤’ğŸ¤’å‡ºäº†ä¸€ç‚¹å°é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•ä¸‹...';
    }

    return response;
  }

}


const clearMap = async () => {
  const now = Date.now();
  const promises = Array.from(conversationPool.entries())
    .filter(([key, value]) => now - value.datatime >= 1000 * 600)
    .map(([key, value]) =>
      new Promise((resolve, reject) => {
        conversationPool.delete(key);
        resolve();
      })
    );

  try {
    await Promise.all(promises);
    console.log('Keys deleted successfully');
    //   console.log(conversationPool);
  } catch (err) {
    console.error(err);
  }
};

// æ¯éš”30åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡clearMap()æ–¹æ³•
schedule.scheduleJob('*/30 * * * *', clearMap);


export default chatgptReply